{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Distributed Collective Operations\n\nThis notebook demonstrates HPX collective communication patterns running across multiple localities (processes). Each collective is executed by a worker script that runs on every locality simultaneously (SPMD pattern).\n\n**Collectives demonstrated:**\n1. **all_reduce** - combine local values, result available on all localities\n2. **broadcast** - send data from root to all localities\n3. **gather** - collect data from all localities to root\n4. **scatter** - distribute chunks from root to all localities\n5. **barrier** - synchronize all localities",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%writefile _distributed_reduction_worker.py\n\"\"\"SPMD collective operations demo.\n\nEach locality runs this script. Collectives coordinate across all localities.\n\"\"\"\nimport sys\nimport numpy as np\nimport hpxpy as hpx\nfrom hpxpy.launcher import init_from_args\n\ninit_from_args()\n\nmy_id = hpx.locality_id()\nnum_locs = hpx.num_localities()\nprint(f\"[Locality {my_id}/{num_locs}] Started with {hpx.num_threads()} threads\")\n\n# ============================================================\n# 1. ALL-REDUCE: each locality contributes, all get the result\n# ============================================================\nprint(f\"\\n{'='*50}\")\nprint(\"Phase 1: All-Reduce\")\nprint(f\"{'='*50}\")\n\n# Each locality has different local data\nnp.random.seed(100 + my_id)\nlocal_values = np.random.randn(5)\nlocal_arr = hpx.from_numpy(local_values)\n\nlocal_sum = float(hpx.sum(local_arr))\nprint(f\"[Locality {my_id}] Local values: {local_values.round(2)}\")\nprint(f\"[Locality {my_id}] Local sum: {local_sum:.4f}\")\n\n# All-reduce combines across localities; every locality gets the result\nglobal_arr = hpx.all_reduce(local_arr, op='sum')\nglobal_sum = float(hpx.sum(global_arr))\nprint(f\"[Locality {my_id}] Global sum after all_reduce: {global_sum:.4f}\")\n\nhpx.barrier(\"after_allreduce\")\n\n# ============================================================\n# 2. BROADCAST: root sends data to all localities\n# ============================================================\nprint(f\"\\n{'='*50}\")\nprint(\"Phase 2: Broadcast\")\nprint(f\"{'='*50}\")\n\nif my_id == 0:\n    params = np.array([0.01, 0.9, 256.0])  # learning_rate, momentum, batch_size\n    print(f\"[Locality 0] Broadcasting parameters: {params}\")\nelse:\n    params = np.zeros(3)\n\nparams_arr = hpx.from_numpy(params)\nreceived = hpx.broadcast(params_arr, root=0)\nprint(f\"[Locality {my_id}] Received: {received.to_numpy()}\")\n\nhpx.barrier(\"after_broadcast\")\n\n# ============================================================\n# 3. GATHER: all localities send to root\n# ============================================================\nprint(f\"\\n{'='*50}\")\nprint(\"Phase 3: Gather\")\nprint(f\"{'='*50}\")\n\n# Each locality computes local statistics\nlocal_mean = float(np.mean(local_values))\nlocal_std = float(np.std(local_values))\nmy_stats = hpx.from_numpy(np.array([local_mean, local_std, float(len(local_values))]))\nprint(f\"[Locality {my_id}] Sending stats: mean={local_mean:.4f}, std={local_std:.4f}, n={len(local_values)}\")\n\ngathered = hpx.gather(my_stats, root=0)\n\nif my_id == 0:\n    print(f\"[Locality 0] Gathered from {len(gathered)} localities:\")\n    for i, stats in enumerate(gathered):\n        print(f\"  Locality {i}: mean={stats[0]:.4f}, std={stats[1]:.4f}, n={int(stats[2])}\")\n\nhpx.barrier(\"after_gather\")\n\n# ============================================================\n# 4. SCATTER: root distributes chunks to each locality\n# ============================================================\nprint(f\"\\n{'='*50}\")\nprint(\"Phase 4: Scatter\")\nprint(f\"{'='*50}\")\n\nif my_id == 0:\n    # Root creates work assignments for each locality\n    all_work = np.arange(num_locs * 4, dtype=np.float64)\n    print(f\"[Locality 0] Scattering work array: {all_work}\")\nelse:\n    all_work = np.empty(0)\n\nwork_arr = hpx.from_numpy(all_work)\nmy_chunk = hpx.scatter(work_arr, root=0)\nprint(f\"[Locality {my_id}] Received chunk: {my_chunk.to_numpy()}\")\n\nhpx.barrier(\"after_scatter\")\n\n# ============================================================\n# 5. BARRIER: synchronize all localities\n# ============================================================\nprint(f\"\\n{'='*50}\")\nprint(\"Phase 5: Barrier\")\nprint(f\"{'='*50}\")\n\nimport time\n# Simulate different amounts of work per locality\ntime.sleep(0.1 * my_id)\nprint(f\"[Locality {my_id}] Finished work, waiting at barrier...\")\nhpx.barrier(\"final_sync\")\nprint(f\"[Locality {my_id}] All localities synchronized!\")\n\nhpx.barrier(\"cleanup\")\nif my_id == 0:\n    print(\"\\nAll phases completed successfully.\")\nhpx.finalize()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Launch Distributed Execution\n\nEach locality runs the same worker script (SPMD). The collectives synchronize data between them via HPX's TCP parcelport.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from hpxpy.launcher import launch_localities\n\nlaunch_localities(\n    \"_distributed_reduction_worker.py\",\n    num_localities=2,\n    threads_per_locality=2,\n    verbose=True,\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Collective Operation Patterns\n\n### All-Reduce\nEvery locality contributes data. The reduction (sum, min, max, prod) is computed and the result is available on **all** localities. Communication: O(N * log(P)) where N is data size, P is localities.\n\n### Broadcast\nOne locality (root) sends data to all others. Communication: O(N * log(P)).\n\n### Gather\nAll localities send their data to the root. Root receives a list of arrays. Communication: O(N * P) at root.\n\n### Scatter\nRoot distributes equal-sized chunks to each locality. Each locality receives its portion. Communication: O(N) total.\n\n### Barrier\nPure synchronization point. No data is exchanged. All localities block until every locality has reached the barrier.\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nos.remove(\"_distributed_reduction_worker.py\")\nprint(\"Cleaned up worker script.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}