{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPXPy Distributed Analytics Demo\n",
    "\n",
    "This notebook benchmarks HPXPy vs NumPy on a data science workflow, demonstrating HPXPy's parallel performance advantage on large datasets.\n",
    "\n",
    "## Use Case: IoT Sensor Network Analytics\n",
    "\n",
    "- Millions of sensor readings from a distributed sensor network\n",
    "- Each reading has: timestamp, sensor_id, temperature, humidity, pressure\n",
    "- Goal: Compute statistics, detect anomalies, compute derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import hpxpy as hpx\n",
    "\n",
    "hpx.init(num_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sensor_data(n_samples):\n",
    "    \"\"\"Simulate IoT sensor network data.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Sensor readings with realistic patterns\n",
    "    timestamps = np.arange(n_samples, dtype=np.float64)\n",
    "    sensor_ids = np.random.randint(0, 1000, n_samples).astype(np.float64)\n",
    "    \n",
    "    # Temperature with daily cycle + noise\n",
    "    base_temp = 20 + 10 * np.sin(2 * np.pi * timestamps / 86400)\n",
    "    temperature = base_temp + np.random.normal(0, 2, n_samples)\n",
    "    \n",
    "    # Humidity inversely correlated with temperature\n",
    "    humidity = 60 - 0.5 * (temperature - 20) + np.random.normal(0, 5, n_samples)\n",
    "    humidity = np.clip(humidity, 0, 100)\n",
    "    \n",
    "    # Pressure with slow drift\n",
    "    pressure = 1013 + 10 * np.sin(2 * np.pi * timestamps / 604800) + np.random.normal(0, 2, n_samples)\n",
    "    \n",
    "    return timestamps, sensor_ids, temperature, humidity, pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Analytics Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_numpy(temperature, humidity, pressure, n_iterations=3):\n",
    "    \"\"\"Benchmark NumPy performance on analytics pipeline.\"\"\"\n",
    "    times = []\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        # Statistics\n",
    "        temp_mean = np.mean(temperature)\n",
    "        temp_std = np.std(temperature)\n",
    "        humid_mean = np.mean(humidity)\n",
    "        humid_std = np.std(humidity)\n",
    "        press_mean = np.mean(pressure)\n",
    "        press_std = np.std(pressure)\n",
    "        \n",
    "        # Anomaly detection (z-score)\n",
    "        temp_zscore = np.abs(temperature - temp_mean) / temp_std\n",
    "        humid_zscore = np.abs(humidity - humid_mean) / humid_std\n",
    "        press_zscore = np.abs(pressure - press_mean) / press_std\n",
    "        \n",
    "        n_temp_anomalies = np.sum(temp_zscore > 3.0)\n",
    "        n_humid_anomalies = np.sum(humid_zscore > 3.0)\n",
    "        n_press_anomalies = np.sum(press_zscore > 3.0)\n",
    "        \n",
    "        # Feature engineering\n",
    "        heat_index = temperature * 1.8 + 32 + humidity * 0.1\n",
    "        dew_point = temperature - ((100 - humidity) / 5)\n",
    "        pressure_tendency = (pressure - press_mean) / press_std\n",
    "        comfort = 100 - np.abs(temperature - 22) * 2 - np.abs(humidity - 50) * 0.5\n",
    "        \n",
    "        # Final reductions\n",
    "        _ = np.mean(heat_index)\n",
    "        _ = np.mean(dew_point)\n",
    "        _ = np.mean(comfort)\n",
    "        \n",
    "        elapsed = time.perf_counter() - start\n",
    "        times.append(elapsed)\n",
    "    \n",
    "    return min(times), {\n",
    "        'temp_mean': temp_mean, 'temp_std': temp_std,\n",
    "        'n_temp_anomalies': n_temp_anomalies,\n",
    "        'n_humid_anomalies': n_humid_anomalies,\n",
    "        'n_press_anomalies': n_press_anomalies\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPXPy Analytics Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_hpxpy(temp_hpx, humid_hpx, press_hpx, n_iterations=3):\n",
    "    \"\"\"Benchmark HPXPy performance on analytics pipeline.\"\"\"\n",
    "    times = []\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        # Statistics\n",
    "        temp_mean = hpx.mean(temp_hpx)\n",
    "        temp_std = hpx.std(temp_hpx)\n",
    "        humid_mean = hpx.mean(humid_hpx)\n",
    "        humid_std = hpx.std(humid_hpx)\n",
    "        press_mean = hpx.mean(press_hpx)\n",
    "        press_std = hpx.std(press_hpx)\n",
    "        \n",
    "        # Anomaly detection (z-score)\n",
    "        temp_zscore = hpx.abs(temp_hpx - temp_mean) / temp_std\n",
    "        humid_zscore = hpx.abs(humid_hpx - humid_mean) / humid_std\n",
    "        press_zscore = hpx.abs(press_hpx - press_mean) / press_std\n",
    "        \n",
    "        temp_anomaly = (temp_zscore > 3.0).to_numpy().astype(np.float64)\n",
    "        humid_anomaly = (humid_zscore > 3.0).to_numpy().astype(np.float64)\n",
    "        press_anomaly = (press_zscore > 3.0).to_numpy().astype(np.float64)\n",
    "        \n",
    "        n_temp_anomalies = int(hpx.sum(hpx.from_numpy(temp_anomaly)))\n",
    "        n_humid_anomalies = int(hpx.sum(hpx.from_numpy(humid_anomaly)))\n",
    "        n_press_anomalies = int(hpx.sum(hpx.from_numpy(press_anomaly)))\n",
    "        \n",
    "        # Feature engineering\n",
    "        heat_index = temp_hpx * 1.8 + 32 + humid_hpx * 0.1\n",
    "        dew_point = temp_hpx - ((100 - humid_hpx) / 5)\n",
    "        pressure_tendency = (press_hpx - press_mean) / press_std\n",
    "        comfort = 100 - hpx.abs(temp_hpx - 22) * 2 - hpx.abs(humid_hpx - 50) * 0.5\n",
    "        \n",
    "        # Final reductions\n",
    "        _ = hpx.mean(heat_index)\n",
    "        _ = hpx.mean(dew_point)\n",
    "        _ = hpx.mean(comfort)\n",
    "        \n",
    "        elapsed = time.perf_counter() - start\n",
    "        times.append(elapsed)\n",
    "    \n",
    "    return min(times), {\n",
    "        'temp_mean': temp_mean, 'temp_std': temp_std,\n",
    "        'n_temp_anomalies': n_temp_anomalies,\n",
    "        'n_humid_anomalies': n_humid_anomalies,\n",
    "        'n_press_anomalies': n_press_anomalies\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: Full Analytics Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_localities = hpx.distribution.get_num_localities()\n",
    "locality_id = hpx.distribution.get_locality_id()\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  HPX Threads: 4\")\n",
    "print(f\"  Localities: {n_localities}\")\n",
    "print(f\"  Current locality: {locality_id}\")\n",
    "\n",
    "# Test multiple dataset sizes\n",
    "sizes = [1_000_000, 5_000_000, 10_000_000]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Benchmark: Full Analytics Pipeline\")\n",
    "print(\"  (statistics + anomaly detection + feature engineering)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{'Dataset Size':>15} | {'NumPy (ms)':>12} | {'HPXPy (ms)':>12} | {'Speedup':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for n_samples in sizes:\n",
    "    # Generate data\n",
    "    _, _, temperature, humidity, pressure = simulate_sensor_data(n_samples)\n",
    "    \n",
    "    # NumPy benchmark\n",
    "    np_time, np_results = benchmark_numpy(temperature, humidity, pressure)\n",
    "    \n",
    "    # HPXPy benchmark\n",
    "    temp_hpx = hpx.from_numpy(temperature)\n",
    "    humid_hpx = hpx.from_numpy(humidity)\n",
    "    press_hpx = hpx.from_numpy(pressure)\n",
    "    \n",
    "    hpx_time, hpx_results = benchmark_hpxpy(temp_hpx, humid_hpx, press_hpx)\n",
    "    \n",
    "    speedup = np_time / hpx_time\n",
    "    \n",
    "    print(f\"{n_samples:>15,} | {np_time*1000:>12.2f} | {hpx_time*1000:>12.2f} | {speedup:>9.2f}x\")\n",
    "    \n",
    "    # Verify correctness\n",
    "    assert abs(np_results['temp_mean'] - hpx_results['temp_mean']) < 0.01\n",
    "    assert np_results['n_humid_anomalies'] == hpx_results['n_humid_anomalies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Operation Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10_000_000\n",
    "_, _, temperature, humidity, pressure = simulate_sensor_data(n_samples)\n",
    "temp_hpx = hpx.from_numpy(temperature)\n",
    "humid_hpx = hpx.from_numpy(humidity)\n",
    "\n",
    "operations = []\n",
    "\n",
    "# Reduction: sum\n",
    "start = time.perf_counter()\n",
    "for _ in range(5):\n",
    "    _ = np.sum(temperature)\n",
    "np_sum = (time.perf_counter() - start) / 5\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(5):\n",
    "    _ = hpx.sum(temp_hpx)\n",
    "hpx_sum = (time.perf_counter() - start) / 5\n",
    "operations.append(('sum (reduction)', np_sum, hpx_sum))\n",
    "\n",
    "# Element-wise: sqrt\n",
    "start = time.perf_counter()\n",
    "for _ in range(5):\n",
    "    _ = np.sqrt(temperature + 50)\n",
    "np_sqrt = (time.perf_counter() - start) / 5\n",
    "\n",
    "temp_shifted = hpx.from_numpy(temperature + 50)\n",
    "start = time.perf_counter()\n",
    "for _ in range(5):\n",
    "    _ = hpx.sqrt(temp_shifted)\n",
    "hpx_sqrt = (time.perf_counter() - start) / 5\n",
    "operations.append(('sqrt (element-wise)', np_sqrt, hpx_sqrt))\n",
    "\n",
    "# Compute-heavy: chained math operations\n",
    "start = time.perf_counter()\n",
    "for _ in range(3):\n",
    "    r = np.sin(temperature * 0.1)\n",
    "    r = np.exp(r * 0.5)\n",
    "    r = np.sqrt(np.abs(r))\n",
    "    _ = np.sum(r)\n",
    "np_heavy = (time.perf_counter() - start) / 3\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(3):\n",
    "    r = hpx.sin(temp_hpx * 0.1)\n",
    "    r = hpx.exp(r * 0.5)\n",
    "    r = hpx.sqrt(hpx.abs(r))\n",
    "    _ = hpx.sum(r)\n",
    "hpx_heavy = (time.perf_counter() - start) / 3\n",
    "operations.append(('sin+exp+sqrt chain', np_heavy, hpx_heavy))\n",
    "\n",
    "print(f\"\\n{'Operation':>25} | {'NumPy (ms)':>12} | {'HPXPy (ms)':>12} | {'Speedup':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for op_name, np_t, hpx_t in operations:\n",
    "    speedup = np_t / hpx_t\n",
    "    print(f\"{op_name:>25} | {np_t*1000:>12.2f} | {hpx_t*1000:>12.2f} | {speedup:>9.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key factors for HPXPy performance:\n",
    "\n",
    "1. **SIMD vectorization** (`-march=native -ffast-math`)\n",
    "2. **GIL released** during C++ execution\n",
    "3. **Parallel element-wise operations** (`hpx::for_each`)\n",
    "4. **Deterministic sequential reductions**\n",
    "\n",
    "The real power comes from distributed execution across multiple nodes, where HPX's AGAS enables seamless data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpx.finalize()\n",
    "print(\"Benchmark complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
