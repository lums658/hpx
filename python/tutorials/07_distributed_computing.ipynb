{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Distributed Computing with HPXPy\n",
    "\n",
    "HPXPy supports distributed computing across multiple processes (localities). This tutorial covers:\n",
    "\n",
    "- Collective operations (all_reduce, broadcast, gather, scatter)\n",
    "- Distributed arrays\n",
    "- Distribution policies\n",
    "- Multi-locality concepts\n",
    "\n",
    "**Note**: In single-locality mode (one process), collective operations return sensible defaults. The full power of these features is realized when running across multiple localities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.333613Z",
     "iopub.status.busy": "2026-01-14T00:54:16.333529Z",
     "iopub.status.idle": "2026-01-14T00:54:16.533656Z",
     "shell.execute_reply": "2026-01-14T00:54:16.532494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPXPy version: 0.1.0\n",
      "Number of localities: 1\n",
      "Current locality ID: 0\n",
      "Number of threads: 12\n"
     ]
    }
   ],
   "source": [
    "import hpxpy as hpx\n",
    "import numpy as np\n",
    "\n",
    "# Initialize HPX runtime\n",
    "hpx.init()\n",
    "\n",
    "print(f\"HPXPy version: {hpx.__version__}\")\n",
    "print(f\"Number of localities: {hpx.num_localities()}\")\n",
    "print(f\"Current locality ID: {hpx.locality_id()}\")\n",
    "print(f\"Number of threads: {hpx.num_threads()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectives-header",
   "metadata": {},
   "source": [
    "## 1. Collective Operations\n",
    "\n",
    "Collective operations are communication patterns that involve all localities in a distributed computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allreduce-header",
   "metadata": {},
   "source": [
    "### All-Reduce\n",
    "\n",
    "Combines values from all localities and distributes the result to everyone.\n",
    "\n",
    "```\n",
    "Locality 0: [1, 2, 3]  ─┐\n",
    "Locality 1: [4, 5, 6]  ─┼─► all_reduce(sum) ─► [5, 7, 9] (to all)\n",
    "Locality 2: [0, 0, 0]  ─┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "allreduce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.536739Z",
     "iopub.status.busy": "2026-01-14T00:54:16.536487Z",
     "iopub.status.idle": "2026-01-14T00:54:16.543088Z",
     "shell.execute_reply": "2026-01-14T00:54:16.542002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local data: [1. 2. 3. 4. 5.]\n",
      "\n",
      "All-reduce operations:\n",
      "  sum: [1. 2. 3. 4. 5.]\n",
      "  prod: [1. 2. 3. 4. 5.]\n",
      "  min: [1. 2. 3. 4. 5.]\n",
      "  max: [1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Create local data\n",
    "local_data = hpx.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "print(\"Local data:\", local_data.to_numpy())\n",
    "\n",
    "# All-reduce with different operations\n",
    "print(\"\\nAll-reduce operations:\")\n",
    "print(\"  sum:\", hpx.all_reduce(local_data, op='sum').to_numpy())\n",
    "print(\"  prod:\", hpx.all_reduce(local_data, op='prod').to_numpy())\n",
    "print(\"  min:\", hpx.all_reduce(local_data, op='min').to_numpy())\n",
    "print(\"  max:\", hpx.all_reduce(local_data, op='max').to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allreduce-example",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.548778Z",
     "iopub.status.busy": "2026-01-14T00:54:16.548556Z",
     "iopub.status.idle": "2026-01-14T00:54:16.553320Z",
     "shell.execute_reply": "2026-01-14T00:54:16.552309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global statistics:\n",
      "  Total count: 100.0\n",
      "  Global min: 50.0\n",
      "  Global max: 200.0\n"
     ]
    }
   ],
   "source": [
    "# Practical example: Global statistics\n",
    "# In a distributed setting, each locality would have different local_stats\n",
    "local_stats = hpx.array([100.0, 50.0, 200.0])  # [count, min, max]\n",
    "\n",
    "# Combine across localities\n",
    "global_count = hpx.all_reduce(hpx.array([local_stats[0]]), op='sum')\n",
    "global_min = hpx.all_reduce(hpx.array([local_stats[1]]), op='min')\n",
    "global_max = hpx.all_reduce(hpx.array([local_stats[2]]), op='max')\n",
    "\n",
    "print(\"Global statistics:\")\n",
    "print(f\"  Total count: {global_count.to_numpy()[0]}\")\n",
    "print(f\"  Global min: {global_min.to_numpy()[0]}\")\n",
    "print(f\"  Global max: {global_max.to_numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadcast-header",
   "metadata": {},
   "source": [
    "### Broadcast\n",
    "\n",
    "Sends data from one locality (root) to all other localities.\n",
    "\n",
    "```\n",
    "Locality 0: [1, 2, 3]  ─── broadcast(root=0) ───► [1, 2, 3] (to all)\n",
    "Locality 1: [?, ?, ?]  ─────────────────────────► [1, 2, 3]\n",
    "Locality 2: [?, ?, ?]  ─────────────────────────► [1, 2, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broadcast",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.555639Z",
     "iopub.status.busy": "2026-01-14T00:54:16.555456Z",
     "iopub.status.idle": "2026-01-14T00:54:16.559538Z",
     "shell.execute_reply": "2026-01-14T00:54:16.558815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before broadcast: [3.14159 2.71828 1.41421]\n",
      "After broadcast: [3.14159 2.71828 1.41421]\n"
     ]
    }
   ],
   "source": [
    "# Root locality has the data to share\n",
    "if hpx.locality_id() == 0:\n",
    "    config_data = hpx.array([3.14159, 2.71828, 1.41421])\n",
    "else:\n",
    "    config_data = hpx.zeros(3)  # Placeholder on other localities\n",
    "\n",
    "print(\"Before broadcast:\", config_data.to_numpy())\n",
    "\n",
    "# Broadcast from root=0\n",
    "shared_config = hpx.broadcast(config_data, root=0)\n",
    "print(\"After broadcast:\", shared_config.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gather-header",
   "metadata": {},
   "source": [
    "### Gather\n",
    "\n",
    "Collects data from all localities to a single root locality.\n",
    "\n",
    "```\n",
    "Locality 0: [1, 2]  ─┐\n",
    "Locality 1: [3, 4]  ─┼─► gather(root=0) ─► [[1,2], [3,4], [5,6]] (on root)\n",
    "Locality 2: [5, 6]  ─┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gather",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.561673Z",
     "iopub.status.busy": "2026-01-14T00:54:16.561495Z",
     "iopub.status.idle": "2026-01-14T00:54:16.566000Z",
     "shell.execute_reply": "2026-01-14T00:54:16.565117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My contribution (locality 0): [0 1 2]\n",
      "\n",
      "Gathered 1 arrays at root:\n",
      "  From locality 0: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Each locality contributes its data\n",
    "my_contribution = hpx.array([hpx.locality_id() * 10 + i for i in range(3)])\n",
    "print(f\"My contribution (locality {hpx.locality_id()}):\", my_contribution.to_numpy())\n",
    "\n",
    "# Gather to root\n",
    "all_data = hpx.gather(my_contribution, root=0)\n",
    "\n",
    "if hpx.locality_id() == 0:\n",
    "    print(f\"\\nGathered {len(all_data)} arrays at root:\")\n",
    "    for i, arr in enumerate(all_data):\n",
    "        print(f\"  From locality {i}: {arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scatter-header",
   "metadata": {},
   "source": [
    "### Scatter\n",
    "\n",
    "Distributes portions of data from root to all localities.\n",
    "\n",
    "```\n",
    "Locality 0: [1,2,3,4,5,6] ─► scatter(root=0) ─► [1,2] (to loc 0)\n",
    "                                             ─► [3,4] (to loc 1)\n",
    "                                             ─► [5,6] (to loc 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scatter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.568279Z",
     "iopub.status.busy": "2026-01-14T00:54:16.568082Z",
     "iopub.status.idle": "2026-01-14T00:54:16.572173Z",
     "shell.execute_reply": "2026-01-14T00:54:16.571442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data on root: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      "My chunk (locality 0): [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n"
     ]
    }
   ],
   "source": [
    "# Root has all the data\n",
    "if hpx.locality_id() == 0:\n",
    "    full_data = hpx.arange(12)  # [0, 1, 2, ..., 11]\n",
    "    print(\"Full data on root:\", full_data.to_numpy())\n",
    "else:\n",
    "    full_data = hpx.zeros(12)  # Placeholder\n",
    "\n",
    "# Scatter distributes chunks\n",
    "my_chunk = hpx.scatter(full_data, root=0)\n",
    "print(f\"My chunk (locality {hpx.locality_id()}):\", my_chunk.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "barrier-header",
   "metadata": {},
   "source": [
    "### Barrier\n",
    "\n",
    "Synchronizes all localities - everyone waits until all reach the barrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "barrier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.574549Z",
     "iopub.status.busy": "2026-01-14T00:54:16.574320Z",
     "iopub.status.idle": "2026-01-14T00:54:16.580459Z",
     "shell.execute_reply": "2026-01-14T00:54:16.579403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locality 0 starting computation...\n",
      "Locality 0 passed barrier with result: 499999500000.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Locality {hpx.locality_id()} starting computation...\")\n",
    "\n",
    "# Simulate some work\n",
    "result = hpx.sum(hpx.arange(1000000))\n",
    "\n",
    "# Synchronize before continuing\n",
    "hpx.barrier(\"computation_done\")\n",
    "\n",
    "print(f\"Locality {hpx.locality_id()} passed barrier with result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectives-module-header",
   "metadata": {},
   "source": [
    "### Collectives Module\n",
    "\n",
    "Additional locality functions are available in the `hpx.collectives` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collectives-module",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.583104Z",
     "iopub.status.busy": "2026-01-14T00:54:16.582851Z",
     "iopub.status.idle": "2026-01-14T00:54:16.586812Z",
     "shell.execute_reply": "2026-01-14T00:54:16.585731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Via hpx.collectives module:\n",
      "  Number of localities: 1\n",
      "  Current locality ID: 0\n"
     ]
    }
   ],
   "source": [
    "# Access locality information via collectives module\n",
    "print(\"Via hpx.collectives module:\")\n",
    "print(f\"  Number of localities: {hpx.collectives.get_num_localities()}\")\n",
    "print(f\"  Current locality ID: {hpx.collectives.get_locality_id()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-arrays-header",
   "metadata": {},
   "source": [
    "## 2. Distributed Arrays\n",
    "\n",
    "Distributed arrays span multiple localities with automatic data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distributed-creation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.589198Z",
     "iopub.status.busy": "2026-01-14T00:54:16.589011Z",
     "iopub.status.idle": "2026-01-14T00:54:16.594662Z",
     "shell.execute_reply": "2026-01-14T00:54:16.593813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed zeros:\n",
      "  Shape: [100]\n",
      "  Size: 100\n",
      "  First 10: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Distributed ones:\n",
      "  Shape: [50, 2]\n",
      "  First row: [1. 1.]\n",
      "\n",
      "Distributed full (3.14):\n",
      "  Values: [3.14 3.14 3.14 3.14 3.14 3.14 3.14 3.14 3.14 3.14 3.14 3.14 3.14 3.14\n",
      " 3.14 3.14 3.14 3.14 3.14 3.14]\n"
     ]
    }
   ],
   "source": [
    "# Create distributed arrays\n",
    "d_zeros = hpx.distributed_zeros([100])\n",
    "d_ones = hpx.distributed_ones([50, 2])\n",
    "d_full = hpx.distributed_full([20], 3.14)\n",
    "\n",
    "print(\"Distributed zeros:\")\n",
    "print(f\"  Shape: {d_zeros.shape}\")\n",
    "print(f\"  Size: {d_zeros.size}\")\n",
    "print(f\"  First 10: {d_zeros.to_numpy()[:10]}\")\n",
    "\n",
    "print(\"\\nDistributed ones:\")\n",
    "print(f\"  Shape: {d_ones.shape}\")\n",
    "print(f\"  First row: {d_ones.to_numpy()[0]}\")\n",
    "\n",
    "print(\"\\nDistributed full (3.14):\")\n",
    "print(f\"  Values: {d_full.to_numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "from-numpy-distributed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.596820Z",
     "iopub.status.busy": "2026-01-14T00:54:16.596627Z",
     "iopub.status.idle": "2026-01-14T00:54:16.601570Z",
     "shell.execute_reply": "2026-01-14T00:54:16.600530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From NumPy:\n",
      "  Original: [ 0.          0.52631579  1.05263158  1.57894737  2.10526316  2.63157895\n",
      "  3.15789474  3.68421053  4.21052632  4.73684211  5.26315789  5.78947368\n",
      "  6.31578947  6.84210526  7.36842105  7.89473684  8.42105263  8.94736842\n",
      "  9.47368421 10.        ]\n",
      "  Distributed: [ 0.          0.52631579  1.05263158  1.57894737  2.10526316  2.63157895\n",
      "  3.15789474  3.68421053  4.21052632  4.73684211  5.26315789  5.78947368\n",
      "  6.31578947  6.84210526  7.36842105  7.89473684  8.42105263  8.94736842\n",
      "  9.47368421 10.        ]\n"
     ]
    }
   ],
   "source": [
    "# Create distributed array from NumPy\n",
    "np_data = np.linspace(0, 10, 20)\n",
    "d_arr = hpx.distributed_from_numpy(np_data)\n",
    "\n",
    "print(\"From NumPy:\")\n",
    "print(f\"  Original: {np_data}\")\n",
    "print(f\"  Distributed: {d_arr.to_numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distribution-policies-header",
   "metadata": {},
   "source": [
    "### Distribution Policies\n",
    "\n",
    "Control how data is partitioned across localities:\n",
    "\n",
    "- **none**: No distribution (local array)\n",
    "- **block**: Contiguous chunks to each locality\n",
    "- **cyclic**: Round-robin distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distribution-policies",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.604996Z",
     "iopub.status.busy": "2026-01-14T00:54:16.604458Z",
     "iopub.status.idle": "2026-01-14T00:54:16.607743Z",
     "shell.execute_reply": "2026-01-14T00:54:16.606979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Policies:\n",
      "  None:  DistributionPolicy.none\n",
      "  Block: DistributionPolicy.block\n",
      "  Cyclic: DistributionPolicy.cyclic\n"
     ]
    }
   ],
   "source": [
    "# Available distribution policies\n",
    "print(\"Distribution Policies:\")\n",
    "print(f\"  None:  {hpx.DistributionPolicy.none}\")\n",
    "print(f\"  Block: {hpx.DistributionPolicy.block}\")\n",
    "print(f\"  Cyclic: {hpx.DistributionPolicy.cyclic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "create-with-policy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.610546Z",
     "iopub.status.busy": "2026-01-14T00:54:16.610365Z",
     "iopub.status.idle": "2026-01-14T00:54:16.614462Z",
     "shell.execute_reply": "2026-01-14T00:54:16.613557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution policies:\n",
      "  None policy:   DistributionPolicy.none\n",
      "  Block policy:  DistributionPolicy.block\n",
      "  Cyclic policy: DistributionPolicy.cyclic\n"
     ]
    }
   ],
   "source": [
    "# Create arrays with different distribution policies\n",
    "arr_none = hpx.distributed_zeros([100])  # Default: no distribution\n",
    "arr_block = hpx.distributed_zeros([100], distribution='block')\n",
    "arr_cyclic = hpx.distributed_zeros([100], distribution='cyclic')\n",
    "\n",
    "print(\"Distribution policies:\")\n",
    "print(f\"  None policy:   {arr_none.policy}\")\n",
    "print(f\"  Block policy:  {arr_block.policy}\")\n",
    "print(f\"  Cyclic policy: {arr_cyclic.policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-properties-header",
   "metadata": {},
   "source": [
    "### Distributed Array Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "distributed-properties",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.618179Z",
     "iopub.status.busy": "2026-01-14T00:54:16.617938Z",
     "iopub.status.idle": "2026-01-14T00:54:16.624479Z",
     "shell.execute_reply": "2026-01-14T00:54:16.623314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed Array Properties:\n",
      "  Shape: [1000]\n",
      "  Size: 1000\n",
      "  Dimensions: 1\n",
      "  Policy: DistributionPolicy.block\n",
      "  Num partitions: 1\n",
      "  Locality ID: 0\n",
      "  Is distributed: False\n"
     ]
    }
   ],
   "source": [
    "# Create a distributed array\n",
    "darr = hpx.distributed_ones([1000], distribution='block')\n",
    "\n",
    "print(\"Distributed Array Properties:\")\n",
    "print(f\"  Shape: {darr.shape}\")\n",
    "print(f\"  Size: {darr.size}\")\n",
    "print(f\"  Dimensions: {darr.ndim}\")\n",
    "print(f\"  Policy: {darr.policy}\")\n",
    "print(f\"  Num partitions: {darr.num_partitions}\")\n",
    "print(f\"  Locality ID: {darr.locality_id}\")\n",
    "print(f\"  Is distributed: {darr.is_distributed()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "distribution-info",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.627363Z",
     "iopub.status.busy": "2026-01-14T00:54:16.627070Z",
     "iopub.status.idle": "2026-01-14T00:54:16.633274Z",
     "shell.execute_reply": "2026-01-14T00:54:16.632115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Info:\n",
      "  Policy: DistributionPolicy.block\n",
      "  Num partitions: 1\n",
      "  Chunk size: 1000\n",
      "  Locality ID: 0\n",
      "  Is distributed: False\n"
     ]
    }
   ],
   "source": [
    "# Get detailed distribution information\n",
    "info = darr.get_distribution_info()\n",
    "\n",
    "print(\"Distribution Info:\")\n",
    "print(f\"  Policy: {info.policy}\")\n",
    "print(f\"  Num partitions: {info.num_partitions}\")\n",
    "print(f\"  Chunk size: {info.chunk_size}\")\n",
    "print(f\"  Locality ID: {info.locality_id}\")\n",
    "print(f\"  Is distributed: {info.is_distributed()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-methods-header",
   "metadata": {},
   "source": [
    "### Distributed Array Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "distributed-methods",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.636083Z",
     "iopub.status.busy": "2026-01-14T00:54:16.635645Z",
     "iopub.status.idle": "2026-01-14T00:54:16.641004Z",
     "shell.execute_reply": "2026-01-14T00:54:16.639650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fill: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "After fill(42): [42. 42. 42. 42. 42. 42. 42. 42. 42. 42.]\n"
     ]
    }
   ],
   "source": [
    "# Fill with a value\n",
    "darr = hpx.distributed_zeros([10], distribution='block')\n",
    "print(\"Before fill:\", darr.to_numpy())\n",
    "\n",
    "darr.fill(42.0)\n",
    "print(\"After fill(42):\", darr.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "to-numpy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.645897Z",
     "iopub.status.busy": "2026-01-14T00:54:16.645626Z",
     "iopub.status.idle": "2026-01-14T00:54:16.651069Z",
     "shell.execute_reply": "2026-01-14T00:54:16.649525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Values: [7. 7. 7. 7. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy (gathers all data if distributed)\n",
    "darr = hpx.distributed_full([5], 7.0, distribution='block')\n",
    "\n",
    "np_arr = darr.to_numpy()\n",
    "print(f\"Type: {type(np_arr)}\")\n",
    "print(f\"Values: {np_arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-repr-header",
   "metadata": {},
   "source": [
    "### String Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "distributed-repr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.656534Z",
     "iopub.status.busy": "2026-01-14T00:54:16.656225Z",
     "iopub.status.idle": "2026-01-14T00:54:16.663329Z",
     "shell.execute_reply": "2026-01-14T00:54:16.661689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String representations:\n",
      "  DistributedArrayF64(shape=[100], distribution='none', partitions=1)\n",
      "  DistributedArrayF64(shape=[200], distribution='block', partitions=1)\n",
      "  DistributedArrayF64(shape=[150], distribution='cyclic', partitions=1)\n"
     ]
    }
   ],
   "source": [
    "# See the string representation\n",
    "darr_none = hpx.distributed_zeros([100])\n",
    "darr_block = hpx.distributed_ones([200], distribution='block')\n",
    "darr_cyclic = hpx.distributed_full([150], 5.0, distribution='cyclic')\n",
    "\n",
    "print(\"String representations:\")\n",
    "print(f\"  {repr(darr_none)}\")\n",
    "print(f\"  {repr(darr_block)}\")\n",
    "print(f\"  {repr(darr_cyclic)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multilocality-header",
   "metadata": {},
   "source": [
    "## 3. Multi-Locality Concepts\n",
    "\n",
    "When running with multiple localities, here's how the components work together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spmd-header",
   "metadata": {},
   "source": [
    "### SPMD Pattern (Single Program, Multiple Data)\n",
    "\n",
    "The SPMD pattern runs the same program on all localities, each working on different data:\n",
    "\n",
    "```python\n",
    "# Each locality gets its portion of work\n",
    "my_id = hpx.locality_id()\n",
    "num_locs = hpx.num_localities()\n",
    "\n",
    "# Each locality processes its chunk\n",
    "chunk_size = total_size // num_locs\n",
    "my_start = my_id * chunk_size\n",
    "my_data = process(data[my_start:my_start + chunk_size])\n",
    "\n",
    "# Combine results\n",
    "global_result = hpx.all_reduce(my_data, op='sum')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spmd-example",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.667727Z",
     "iopub.status.busy": "2026-01-14T00:54:16.667480Z",
     "iopub.status.idle": "2026-01-14T00:54:16.689214Z",
     "shell.execute_reply": "2026-01-14T00:54:16.687933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locality 0: local sum = 499999500000.0\n",
      "\n",
      "Global sum: 499999500000.0\n",
      "Expected:   499999500000\n"
     ]
    }
   ],
   "source": [
    "# SPMD example: Distributed sum\n",
    "def distributed_sum_example():\n",
    "    \"\"\"Example of SPMD pattern for distributed computation.\"\"\"\n",
    "    my_id = hpx.locality_id()\n",
    "    num_locs = hpx.num_localities()\n",
    "    \n",
    "    # Total problem size\n",
    "    total_size = 1000000\n",
    "    chunk_size = total_size // num_locs\n",
    "    \n",
    "    # Each locality works on its chunk\n",
    "    my_start = my_id * chunk_size\n",
    "    my_chunk = hpx.arange(my_start, my_start + chunk_size)\n",
    "    \n",
    "    # Compute local sum\n",
    "    local_sum = hpx.sum(my_chunk)\n",
    "    print(f\"Locality {my_id}: local sum = {local_sum}\")\n",
    "    \n",
    "    # Combine across all localities\n",
    "    global_sum = hpx.all_reduce(hpx.array([local_sum]), op='sum')\n",
    "    \n",
    "    return global_sum.to_numpy()[0]\n",
    "\n",
    "result = distributed_sum_example()\n",
    "expected = sum(range(1000000))\n",
    "print(f\"\\nGlobal sum: {result}\")\n",
    "print(f\"Expected:   {expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "launcher-header",
   "metadata": {},
   "source": [
    "### Multi-Locality Launcher\n",
    "\n",
    "HPXPy includes a launcher module for running across multiple processes:\n",
    "\n",
    "```python\n",
    "from hpxpy.launcher import launch_localities, spmd_main\n",
    "\n",
    "# Launch 4 localities running the same script\n",
    "launch_localities(\"my_script.py\", num_localities=4)\n",
    "\n",
    "# Or use the decorator\n",
    "@spmd_main(num_localities=4)\n",
    "def main():\n",
    "    with hpx.runtime():\n",
    "        # Distributed code here\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "launcher-info",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.691948Z",
     "iopub.status.busy": "2026-01-14T00:54:16.691843Z",
     "iopub.status.idle": "2026-01-14T00:54:16.697065Z",
     "shell.execute_reply": "2026-01-14T00:54:16.695699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launcher utilities:\n",
      "  In multi-locality mode: False\n",
      "  Expected localities: 1\n",
      "\n",
      "Example HPX args for locality 0:\n",
      "  --hpx:localities=4\n",
      "  --hpx:hpx=localhost:7910\n",
      "  --hpx:agas=localhost:7910\n"
     ]
    }
   ],
   "source": [
    "# Check launcher utilities\n",
    "from hpxpy.launcher import (\n",
    "    is_multi_locality_mode,\n",
    "    get_expected_num_localities,\n",
    "    LocalityConfig,\n",
    ")\n",
    "\n",
    "print(\"Launcher utilities:\")\n",
    "print(f\"  In multi-locality mode: {is_multi_locality_mode()}\")\n",
    "print(f\"  Expected localities: {get_expected_num_localities()}\")\n",
    "\n",
    "# Example of LocalityConfig\n",
    "config = LocalityConfig(\n",
    "    locality_id=0,\n",
    "    num_localities=4,\n",
    "    host=\"localhost\",\n",
    "    port=7910\n",
    ")\n",
    "print(f\"\\nExample HPX args for locality 0:\")\n",
    "for arg in config.to_hpx_args():\n",
    "    print(f\"  {arg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cleanup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:54:16.701336Z",
     "iopub.status.busy": "2026-01-14T00:54:16.700722Z",
     "iopub.status.idle": "2026-01-14T00:54:16.704773Z",
     "shell.execute_reply": "2026-01-14T00:54:16.704314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime finalized\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "hpx.finalize()\n",
    "print(\"Runtime finalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "### Collective Operations\n",
    "- `all_reduce(arr, op)` - Combine values across localities (sum, prod, min, max)\n",
    "- `broadcast(arr, root)` - Send data from root to all localities\n",
    "- `gather(arr, root)` - Collect data from all localities to root\n",
    "- `scatter(arr, root)` - Distribute data from root to all localities\n",
    "- `barrier(name)` - Synchronize all localities\n",
    "\n",
    "### Distributed Arrays\n",
    "- `distributed_zeros()`, `distributed_ones()`, `distributed_full()`, `distributed_from_numpy()`\n",
    "- Distribution policies: `none`, `block`, `cyclic`\n",
    "- Properties: `shape`, `size`, `ndim`, `policy`, `num_partitions`, `locality_id`\n",
    "- Methods: `to_numpy()`, `fill()`, `is_distributed()`, `get_distribution_info()`\n",
    "\n",
    "### Multi-Locality Support\n",
    "- SPMD pattern for distributed computing\n",
    "- `hpx.launcher` module for multi-process execution\n",
    "- `@spmd_main` decorator for automatic process spawning\n",
    "\n",
    "For more examples, see the `examples/` directory:\n",
    "- `distributed_reduction_demo.py` - SPMD pattern example\n",
    "- `multi_locality_demo.py` - Multi-process launch example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
